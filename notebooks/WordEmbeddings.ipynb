{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "## Reflecting on one hot encoding.\n",
    "\n",
    "Let's start with an example of one hot encoding and consider this simple movie dataset:\n",
    "\n",
    "\n",
    "Movie | Tomato Rating | Genre | Rating | Length \n",
    ":---: | :---: | :---: | :---: | :---:  \n",
    "First Man | 88 | Drama | PG-13 | 138\n",
    "Can You Ever Forgive Me | 98 | Drama | R | 107\n",
    "The Girl in the Spider's Web | 41 | Drama | R | -99\n",
    "Free Solo | 99 | Documentary | PG-13 | 97\n",
    "The Grinch | 57 | Animation | PG | 86\n",
    "Overlord | 80 | Action | R | 109\n",
    "Christopher Robin | 71 | Comedy | PG | -99\n",
    "Ant Man and the Wasp  |  88 | Science Fiction | PG-13 | 118\n",
    "\n",
    "Numeric columns like `Tomato Rating` and `Length` are fine as is but categorical columns (`Genre` and `Rating`) are problematic for machine learning. Simply converting the category values to integers:\n",
    "\n",
    "\n",
    "Movie | Tomato Rating | Genre | Rating | Length \n",
    ":---: | :---: | :---: | :---: | :---:  \n",
    "First Man | 88 | 5 | 2  | 138\n",
    "Can You Ever Forgive Me | 98 | 5 | 3 | 107\n",
    "The Girl in the Spider's Web | 41 | 5 | 3 | -99\n",
    "Free Solo | 99 | 4 | 2 | 97\n",
    "The Grinch | 57 | 2 | 1 | 86\n",
    "Overlord | 80 | 1 | 3 | 109\n",
    "Christopher Robin | 71 | 3 | 1 | -99\n",
    "Ant Man and the Wasp  |  88 | 6 | 2 | 118\n",
    "\n",
    "isn't the answer because that would imply that action (1) is closer to animation (2) than science fiction (6). The solution in this case is to one-hot-encode.\n",
    "\n",
    "\n",
    "\n",
    "After we one hot encode this we get something like:\n",
    "\n",
    "Movie            | Tomato Rating | Action | Animation | Comedy | Documentary | Drama | Science Fiction | PG | PG-13 | R | Length \n",
    ":---: | :---: | :---: | :---: | :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: \n",
    "First Man        | 88            |  0     |    0      |   0    | 0           | 1     | 0    | 0 | 1  |    0| 138\n",
    "Can You Ever Forgive Me | 98 |      0     |    0      |   0    | 0           | 1     | 0    | 0 | 0  |   1|   107\n",
    "The Girl in the Spider's Web | 41 |  0     |    0      |   0    | 0           | 1     | 0    | 0 | 1  |    0|    -99\n",
    "Free Solo | 99 |  0     |    0      |   0    | 1           | 0     | 0    | 0 | 1  |    0|   97\n",
    "The Grinch | 57 |  0     |    1      |   0    | 0           | 0     | 0    | 1 | 0  |    0| 86\n",
    "Overlord | 80 |  1     |    0      |   0    | 0           | 0     | 0    | 0 | 1  |    0|  109\n",
    "Christopher Robin | 71  |  0     |    0      |   1   | 0           | 0     | 0    | 1 | 0  |    0| -99\n",
    "Ant Man and the Wasp   |  0    |    0      |   0    | 0       | 0    | 0     | 1    | 0 | 1  |    0| 118\n",
    "\n",
    "\n",
    "**This is the correct approach for this example.**\n",
    "However, that's a fairly sparse matrix meaning most of the entries are zero. When we one hot encode words in a text document, the matrices are even more sparse. Here is why. Each column represents a word in our vocabulary. That's important so I will write it again: **Each column represents a word in our vocabulary.** We might have 10,000 columns. (The average passive vocabulary of an English speaker is about 40,000 words.) If the first word of our text is word 5,791, then there would be a `1` in that column and a `0` in all the other 9,999 columns. This is shown in the left image below. \n",
    "\n",
    "![word embeddings vs. one hot encoding](https://s3.amazonaws.com/book.keras.io/img/ch6/word_embeddings.png)\n",
    "\n",
    "Instead of the 4 black columns imagine 1,000, 10,00 or more!\n",
    "\n",
    "### A bit of natural language processing history\n",
    "Pre-2000s there was an active research push to create by hand machine readable ontologies. For example, a pianist would be categorized as an instrumentalist, a musician, a human, an animal, a living being, and a physical object. Swimming and floating would have similar attributes but swimming has an agentive quality. The idea was that these ontologies would help in a variety of natural language processing tasks from information retrieval to machine translation.  You can imagine a similar thing being done automatically by analyzing a large corpus. For example, \n",
    "\n",
    "     embarking on a solo career, the pianist performed LIVE from the\n",
    "     The 36-year-old concert pianist performed for students in Vicenza\n",
    "     the legendary pianist performed for Sweetwater's Grand Opening of \n",
    "     acclaimed classical pianist, performed at Chestnut Hill College recently\n",
    "     ---\n",
    "     the jazz pianist played with his trio\n",
    "     the New York-West Stockbridge pianist played a concise program in which \n",
    "     The pianist played several encores.\n",
    "     \n",
    "     In the next 43 minutes, as the violinist performed six classical pieces\n",
    "     The talented young violinist performed with pianist Lianhua Chi.\n",
    "     The violinist performed at the boarding gate for a Delta flight to Brussels, \n",
    "     where the violinist performed the Korngold concerto with the Johannesburg\n",
    "     ---\n",
    "     The violinist played a Hungarian folk song in honour of the Holy Father. \n",
    "     Russian-born violinist, played some of Bach's solo violin sonatas and partitas in a \n",
    "     a professional violinist played the theme live.\n",
    "     \n",
    "From the above, you can see that the words *pianist* and *violinist* occur in the same context and can be seen as sharing similar semantics. Thus, we could write a program that would automatically map words to 200 or 1000 latent categories. *Latent* simply means 'hidden' meaning that we don't specify what those categories are... the program automatically determines these categories.\n",
    "\n",
    "This approach is called **word embeddings**. So instead of\n",
    "\n",
    " word | dog    | hill | man   | on    | saw   | telescope | the   | with\n",
    " ---: | :---: | :---: | :---: | :---: | :---: | :---:     | :---: | :---:  \n",
    " word 1 | 0   |   0   |   0   |   0   |  0    |   0       | 1     | 0\n",
    " word 2 | 0   |   0   |   1   |   0   |  0    |   0       | 0     | 0\n",
    " word 3 | 0   |   0   |   0   |   0   |  1    |   0       | 0     | 0\n",
    " word 4 | 0   |   0   |   0   |   0   |  0    |   0       | 1     | 0\n",
    " word 5 | 1   |   0   |   0   |   0   |  0    |   0       | 0     | 0\n",
    " word 6 | 0   |   0   |   0   |   1   |  0    |   0       | 0     | 0\n",
    " word 7 | 0   |   0   |   0   |   0   |  0    |   0       | 1     | 0\n",
    " word 8 | 0   |   1   |   0   |   0   |  0    |   0       | 0     | 0 \n",
    " word 9 | 0   |   0   |   0   |   0   |  0    |   0       | 0     | 1 \n",
    " word 10 | 0   |   0   |   0   |   0   |  0    |   0       | 1     | 0 \n",
    " word 11 | 0   |   0   |   0   |   0   |  0    |   1       | 0     | 0\n",
    "\n",
    "(where word 1 is the first word in a sentence, word 2 the second), which is one hot encoding, we get something like (where *lf* stands for latent feature):\n",
    "\n",
    "word    | LF1    | LF2     | LF3      | LF4       | LF5      | LF6    | LF7      | LF8\n",
    " ---:   | :---:  | :---:    | :---:    | :---:    | :---:    | :---:        | :---:    | :---:  \n",
    " word 1 | 0.01   |   0.03   |   0.01   |   0.15   |  0.08    |   0.04       | 0.21     | 0.13\n",
    " word 2 | 0.47   |   0.21   |   0.88   |   0.05   |  0.09    |   0.21       | 0.01     | 0.03\n",
    " word 3 | 0.05   |   0.01   |   0.13   |   0.06   |  0.76    |   0.21       | 0.02     | 0.04\n",
    " word 4 | 0.01   |   0.03   |   0.01   |   0.15   |  0.08    |   0.04       | 0.21     | 0.13\n",
    " word 5 | 0.81   |   0.21   |   0.46   |   0.09   |  0.11    |   0.01       | 0.01     | 0.00\n",
    " word 6 | 0.13   |   0.27   |   0.15   |   0.66   |  0.04    |   0.06       | 0.09     | 0.31\n",
    " word 7 | 0.01   |   0.03   |   0.01   |   0.15   |  0.08    |   0.04       | 0.21     | 0.13\n",
    " word 8 | 0.21   |   0.91   |   0.21   |   0.17   |  0.05    |   0.05       | 0.21     | 0.11\n",
    " word 9 | 0.05   |   0.01   |   0.11   |   0.41   |  0.14    |   0.11       | 0.29     | 0.88\n",
    " word 10 | 0.01   |   0.03   |   0.01   |   0.15   |  0.08    |   0.04       | 0.21     | 0.13\n",
    " word 11 | 0.33   |   0.17   |   0.37   |   0.11   |  0.41    |   0.78       | 0.03     | 0.10\n",
    " \n",
    " \n",
    " Keep in mind that this is a toy example. A more typical example might have a one hot encoding representation of 10,000 columns or more (representing a vocabulary of 10,000 most frequent words in the text). This is a **sparse** representation.  The word embedding method might have 200 to 1,000 columns which can represent a much larger vocabulary. This is a **dense** representation.\n",
    " \n",
    " \n",
    "Once again, while the vectors obtained through one-hot encoding are binary, sparse (mostly made of zeros) and very high-dimensional (same dimensionality as the \n",
    "number of words in the vocabulary), \"word embeddings\" are low-dimensional floating point vectors \n",
    "(i.e. \"dense\" vectors, as opposed to sparse vectors). \n",
    "Unlike word vectors obtained via one-hot encoding, word embeddings are learned from data. \n",
    "It is common to see word embeddings that are 256-dimensional, 512-dimensional, or 1024-dimensional when dealing with very large vocabularies. \n",
    "On the other hand, one-hot encoding words generally leads to vectors that are 20,000-dimensional or higher (capturing a vocabulary of 20,000 \n",
    "token in this case). So, word embeddings pack more information into far fewer dimensions. \n",
    "\n",
    "There are two ways to obtain word embeddings:\n",
    "\n",
    "* Learn word embeddings jointly with the main task you care about (e.g. document classification or sentiment prediction). \n",
    "In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network.\n",
    "* Load into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve. \n",
    "These are called \"pre-trained word embeddings\". \n",
    "\n",
    "Let's take a look at both.\n",
    "\n",
    "## Learning word embeddings with the `Embedding` layer\n",
    "\n",
    "\n",
    "The simplest way to associate a dense vector to a word would be to pick the vector at random. The problem with this approach is that the \n",
    "resulting embedding space would have no structure: for instance, the words \"accurate\" and \"exact\" may end up with completely different \n",
    "embeddings, even though they are interchangeable in most sentences. It would be very difficult for a deep neural network to make sense of \n",
    "such a noisy, unstructured embedding space. \n",
    "\n",
    "To get a bit more abstract: the geometric relationships between word vectors should reflect the semantic relationships between these words. \n",
    "Word embeddings are meant to map human language into a geometric space. For instance, in a reasonable embedding space, we would expect \n",
    "synonyms to be embedded into similar word vectors, and in general we would expect the geometric distance (e.g. L2 distance) between any two \n",
    "word vectors to relate to the semantic distance of the associated words (words meaning very different things would be embedded to points \n",
    "far away from each other, while related words would be closer). Even beyond mere distance, we may want specific __directions__ in the \n",
    "embedding space to be meaningful. \n",
    "\n",
    "[...]\n",
    "\n",
    "\n",
    "In real-world word embedding spaces, common examples of meaningful geometric transformations are \"gender vectors\" and \"plural vector\". For \n",
    "instance, by adding a \"female vector\" to the vector \"king\", one obtain the vector \"queen\". By adding a \"plural vector\", one obtain \"kings\". \n",
    "Word embedding spaces typically feature thousands of such interpretable and potentially useful vectors.\n",
    "\n",
    "Is there some \"ideal\" word embedding space that would perfectly map human language and could be used for any natural language processing \n",
    "task? Possibly, but in any case, we have yet to compute anything of the sort. Also, there isn't such a thing as \"human language\", there are \n",
    "many different languages and they are not isomorphic, as a language is the reflection of a specific culture and a specific context. But more \n",
    "pragmatically, what makes a good word embedding space depends heavily on your task: the perfect word embedding space for an \n",
    "English-language movie review sentiment analysis model may look very different from the perfect embedding space for an English-language \n",
    "legal document classification model, because the importance of certain semantic relationships varies from task to task.\n",
    "\n",
    "It is thus reasonable to __learn__ a new embedding space with every new task. Thankfully, backpropagation makes this really easy, and Keras makes it \n",
    "even easier. It's just about learning the weights of a layer: the `Embedding` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# The Embedding layer takes at least two arguments:\n",
    "# the number of possible tokens, here 1000 (1 + maximum word index),\n",
    "# and the dimensionality of the embeddings, here 64.\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Embedding` layer is best understood as a dictionary mapping integer indices (which stand for specific words) to dense vectors. It takes \n",
    "as input integers, it looks up these integers into an internal dictionary, and it returns the associated vectors. It's effectively a dictionary lookup.\n",
    "\n",
    "The `Embedding` layer takes as input a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of \n",
    "integers. It can embed sequences of variable lengths, so for instance we could feed into our embedding layer above batches that could have \n",
    "shapes `(32, 10)` (batch of 32 sequences of length 10) or `(64, 15)` (batch of 64 sequences of length 15). All sequences in a batch must \n",
    "have the same length, though (since we need to pack them into a single tensor), so sequences that are shorter than others should be padded \n",
    "with zeros, and sequences that are longer should be truncated.\n",
    "\n",
    "This layer returns a 3D floating point tensor, of shape `(samples, sequence_length, embedding_dimensionality)`. Such a 3D tensor can then \n",
    "be processed by a  1D convolution layer, which will be introduced in the next section.\n",
    "\n",
    "When you instantiate an `Embedding` layer, its weights (its internal dictionary of token vectors) are initially random, just like with any \n",
    "other layer. During training, these word vectors will be gradually adjusted via backpropagation, structuring the space into something that the \n",
    "downstream model can exploit. Once fully trained, your embedding space will show a lot of structure -- a kind of structure specialized for \n",
    "the specific problem you were training your model for.\n",
    "\n",
    "Let's apply this idea to the IMDB movie review sentiment prediction task. \n",
    "\n",
    "## The IMDB dataset\n",
    "\n",
    "\n",
    "We'll be working with \"IMDB dataset\", a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 \n",
    "reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews.\n",
    "\n",
    "Why do we have these two separate training and test sets? You should never test a machine learning model on the same data that you used to \n",
    "train it! Just because a model performs well on its training data doesn't mean that it will perform well on data it has never seen, and \n",
    "what you actually care about is your model's performance on new data (since you already know the labels of your training data -- obviously \n",
    "you don't need your model to predict those). For instance, it is possible that your model could end up merely _memorizing_ a mapping between \n",
    "your training samples and their targets -- which would be completely useless for the task of predicting targets for data never seen before. \n",
    "\n",
    "\n",
    "The IMDB dataset comes packaged with Keras. It has already been preprocessed: the reviews (sequences of words) \n",
    "have been turned into sequences of integers, where each integer stands for a specific word in a dictionary.\n",
    "\n",
    "The following code will load the dataset (when you run it for the first time, about 80MB of data will be downloaded to your machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `num_words=10000` means that we will only keep the top 10,000 most frequently occurring words in the training data. Rare words \n",
    "will be discarded. This allows us to work with vector data of manageable size.\n",
    "\n",
    "The variables `train_data` and `test_data` are lists of reviews, each review being a list of word indices (encoding a sequence of words). \n",
    "`train_labels` and `test_labels` are lists of 0s and 1s, where 0 stands for \"negative\" and 1 stands for \"positive\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we restricted ourselves to the top 10,000 most frequent words, no word index will exceed 10,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kicks, here's how you can quickly decode one of these reviews back to English words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "# We reverse it, mapping integer indices to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# We decode the review; note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "Let's prepare the data.  We will restrict the movie reviews to the top 10,000 most common words, \n",
    "and cut the reviews after 100 words. Our network will simply learn 8-dimensional embeddings for each of the 10,000 words, turn the \n",
    "input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the tensor to 2D, and train a single `Dense` \n",
    "layer on top for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# Number of words to consider as features\n",
    "max_features = 10000\n",
    "# Cut texts after this number of words \n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "\n",
    "# Load the data as lists of integers.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# This turns our lists of integers\n",
    "# into a 2D integer tensor of shape `(samples, maxlen)`\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 80,801\n",
      "Trainable params: 80,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 87us/step - loss: 0.6226 - acc: 0.6764 - val_loss: 0.4761 - val_acc: 0.8038\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.3736 - acc: 0.8502 - val_loss: 0.3532 - val_acc: 0.8464\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 57us/step - loss: 0.2875 - acc: 0.8832 - val_loss: 0.3280 - val_acc: 0.8578\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2484 - acc: 0.9001 - val_loss: 0.3241 - val_acc: 0.8574\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.2211 - acc: 0.9123 - val_loss: 0.3237 - val_acc: 0.8602\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.1994 - acc: 0.9236 - val_loss: 0.3296 - val_acc: 0.8578\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.1790 - acc: 0.9329 - val_loss: 0.3356 - val_acc: 0.8576\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.1613 - acc: 0.9405 - val_loss: 0.3439 - val_acc: 0.8562\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.1444 - acc: 0.9476 - val_loss: 0.3540 - val_acc: 0.8542\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.1282 - acc: 0.9556 - val_loss: 0.3642 - val_acc: 0.8548\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# We specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "# After the Embedding layer, \n",
    "# our activations have shape `(samples, maxlen, 8)`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings \n",
    "# into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add the classifier on top\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to a validation accuracy of ~85%, which is pretty good considering that we only look at the first 100 words in every review. But \n",
    "note that merely flattening the embedded sequences and training a single `Dense` layer on top leads to a model that treats each word in the \n",
    "input sequence separately, without considering inter-word relationships and structure sentence (e.g. it would likely treat both _\"this movie \n",
    "is shit\"_ and _\"this movie is the shit\"_ as being negative \"reviews\"). It would be much better to add  1D convolutional \n",
    "layers on top of the embedded sequences to learn features that take into account each sequence as a whole. That's what we will focus on in \n",
    "the next few sections.\n",
    "\n",
    "## Using pre-trained word embeddings\n",
    "\n",
    "\n",
    "Sometimes, you have so little training data available that could never use your data alone to learn an appropriate task-specific embedding \n",
    "of your vocabulary. What to do then?\n",
    "\n",
    "Instead of learning word embeddings jointly with the problem you want to solve, you could be loading embedding vectors from a pre-computed \n",
    "embedding space known to be highly structured and to exhibit useful properties -- that captures generic aspects of language structure. The \n",
    "rationale behind using pre-trained word embeddings in natural language processing is very much the same as for using pre-trained convnets \n",
    "in image classification: we don't have enough data available to learn truly powerful features on our own, but we expect the features that \n",
    "we need to be fairly generic, i.e. common visual features or semantic features. In this case it makes sense to reuse features learned on a \n",
    "different problem.\n",
    "\n",
    "Such word embeddings are generally computed using word occurrence statistics (observations about what words co-occur in sentences or \n",
    "documents), using a variety of techniques, some involving neural networks, others not. The idea of a dense, low-dimensional embedding space \n",
    "for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s, but it only started really taking \n",
    "off in research and industry applications after the release of one of the most famous and successful word embedding scheme: the Word2Vec \n",
    "algorithm, developed by Mikolov at Google in 2013. Word2Vec dimensions capture specific semantic properties, e.g. gender.\n",
    "\n",
    "There are various pre-computed databases of word embeddings that can download and start using in a Keras `Embedding` layer. Word2Vec is one \n",
    "of them. Another popular one is called \"GloVe\", developed by Stanford researchers in 2014. It stands for \"Global Vectors for Word \n",
    "Representation\", and it is an embedding technique based on factorizing a matrix of word co-occurrence statistics. Its developers have made \n",
    "available pre-computed embeddings for millions of English tokens, obtained from Wikipedia data or from Common Crawl data.\n",
    "\n",
    "Let's take a look at how you can get started using GloVe embeddings in a Keras model. The same method will of course be valid for Word2Vec \n",
    "embeddings or any other word embedding database that you can download. We will also use this example to refresh the text tokenization \n",
    "techniques we introduced a few paragraphs ago: we will start from raw text, and work our way up.\n",
    "\n",
    "## Putting it all together: from raw text to word embeddings\n",
    "\n",
    "\n",
    "We will be using a model similar to the one we just went over -- embedding sentences in sequences of vectors, flattening them and training a \n",
    "`Dense` layer on top. But we will do it using pre-trained word embeddings, and instead of using the pre-tokenized IMDB data packaged in \n",
    "Keras, we will start from scratch, by downloading the original text data.\n",
    "\n",
    "### Download the IMDB data as raw text\n",
    "\n",
    "\n",
    "First, head to `http://ai.stanford.edu/~amaas/data/sentiment/` and download the raw IMDB dataset (if the URL isn't working anymore, just \n",
    "Google \"IMDB dataset\"). Uncompress it.\n",
    "\n",
    "Now let's collect the individual training reviews into a list of strings, one string per review, and let's also collect the review labels \n",
    "(positive / negative) into a `labels` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = '/home/skool/data/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the data\n",
    "\n",
    "\n",
    "Let's vectorize the texts we collected, and prepare a training and validation split.\n",
    "We will merely be using the concepts we introduced earlier in this section.\n",
    "\n",
    "Because pre-trained word embeddings are meant to be particularly useful on problems where little training data is available (otherwise, \n",
    "task-specific embeddings are likely to outperform them), we will add the following twist: we restrict the training data to its first 200 \n",
    "samples. So we will be learning to classify movie reviews after looking at just 200 examples...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100  # We will cut reviews after 100 words\n",
    "training_samples = 200  # We will be training on 200 samples\n",
    "validation_samples = 10000  # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the GloVe word embeddings\n",
    "\n",
    "\n",
    "Head to `https://nlp.stanford.edu/projects/glove/` (where you can learn more about the GloVe algorithm), and download the pre-computed \n",
    "embeddings from 2014 English Wikipedia. It's a 822MB zip file named `glove.6B.zip`, containing 100-dimensional embedding vectors for \n",
    "400,000 words (or non-word tokens). Un-zip it.\n",
    "\n",
    "### Pre-process the embeddings\n",
    "\n",
    "\n",
    "Let's parse the un-zipped file (it's a `txt` file) to build an index mapping words (as strings) to their vector representation (as number \n",
    "vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = '/home/skool/data/glove'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can do it.   10xp\n",
    "\n",
    "#### Part 1 5xp\n",
    "If the embeddings truly represent the semanatics, then we would think semantically similar words like *doctor* and *physician* would have similar looking vectors compared to *doctor* to *chair*.  We have used `pyplot` before so we should be able to do this. Can you create two **line** plots.\n",
    "\n",
    "1. One showing the semantics of *doctor* and *physician*\n",
    "2. The other showing the semantics of *doctor* and *chair*\n",
    "\n",
    "Does one plot look more similar than the other?\n",
    "\n",
    "#### Part 2: bias in word embeddings 5xp\n",
    "Determine how you would measure how close 2 words are. Is the word *physician* closer to the words *man* or *woman*. What about *programmer* to *man* and *woman*? Can you try a few others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build an embedding matrix that we will be able to load into an `Embedding` layer. It must be a matrix of shape `(max_words, \n",
    "embedding_dim)`, where each entry `i` contains the `embedding_dim`-dimensional vector for the word of index `i` in our reference word index \n",
    "(built during tokenization). Note that the index `0` is not supposed to stand for any word or token -- it's a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model\n",
    "\n",
    "We will be using the same model architecture as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GloVe embeddings in the model\n",
    "\n",
    "\n",
    "The `Embedding` layer has a single weight matrix: a 2D float matrix where each entry `i` is the word vector meant to be associated with \n",
    "index `i`. Simple enough. Let's just load the GloVe matrix we prepared into our `Embedding` layer, the first layer in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Additionally, we freeze the embedding layer (we set its `trainable` attribute to `False`), following the same rationale as what you are \n",
    "already familiar with in the context of pre-trained convnet features: when parts of a model are pre-trained (like our `Embedding` layer), \n",
    "and parts are randomly initialized (like our classifier), the pre-trained parts should not be updated during training to avoid forgetting \n",
    "what they already know. The large gradient update triggered by the randomly initialized layers would be very disruptive to the already \n",
    "learned features.\n",
    "\n",
    "### Train and evaluate\n",
    "\n",
    "Let's compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6592 - acc: 0.4950 - val_loss: 0.7075 - val_acc: 0.5249\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5808 - acc: 0.6450 - val_loss: 0.8115 - val_acc: 0.5065\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5168 - acc: 0.7500 - val_loss: 0.7427 - val_acc: 0.5374\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2850 - acc: 0.9250 - val_loss: 0.9578 - val_acc: 0.5085\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3033 - acc: 0.8650 - val_loss: 0.7394 - val_acc: 0.5503\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1700 - acc: 0.9650 - val_loss: 0.8606 - val_acc: 0.5167\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1293 - acc: 0.9850 - val_loss: 2.0139 - val_acc: 0.4935\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2479 - acc: 0.8700 - val_loss: 0.6930 - val_acc: 0.5976\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0612 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.5944\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.7583 - val_acc: 0.5821\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot its performance over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model quickly starts overfitting, unsurprisingly given the small number of training samples. Validation accuracy has high variance for \n",
    "the same reason, but seems to reach high 50s.\n",
    "\n",
    "Note that your mileage may vary: since we have so few training samples, performance is heavily dependent on which exact 200 samples we \n",
    "picked, and we picked them at random. If it worked really poorly for you, try picking a different random set of 200 samples, just for the \n",
    "sake of the exercise (in real life you don't get to pick your training data).\n",
    "\n",
    "We can also try to train the same model without loading the pre-trained word embeddings and without freezing the embedding layer. In that \n",
    "case, we would be learning a task-specific embedding of our input tokens, which is generally more powerful than pre-trained word embeddings \n",
    "when lots of data is available. However, in our case, we have only 200 training samples. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7023 - acc: 0.4500 - val_loss: 0.6922 - val_acc: 0.5113\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5125 - acc: 0.9850 - val_loss: 0.7023 - val_acc: 0.5048\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2989 - acc: 0.9850 - val_loss: 0.7087 - val_acc: 0.5128\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1268 - acc: 1.0000 - val_loss: 0.7036 - val_acc: 0.5155\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0565 - acc: 1.0000 - val_loss: 0.7112 - val_acc: 0.5186\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.7132 - val_acc: 0.5195\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.7171 - val_acc: 0.5233\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.5221\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.7280 - val_acc: 0.5210\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.7414 - val_acc: 0.5210\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy stalls in the low 50s. So in our case, pre-trained word embeddings does outperform jointly learned embeddings. If you \n",
    "increase the number of training samples, this will quickly stop being the case -- try it as an exercise.\n",
    "\n",
    "Finally, let's evaluate the model on the test data. First, we will need to tokenize the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's load and evaluate the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7452680940437317, 0.52084]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an appalling test accuracy of 52%. Working with just a handful of training samples is hard!\n",
    "\n",
    "# Sequence processing with convolutional neural networks (CNN)\n",
    "\n",
    "Before we turn to Convolutional Neural Networks, let's load the whole dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87393 unique tokens.\n",
      "Shape of data tensor: (25000, 500)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 500  # We will cut reviews after 100 words\n",
    "training_samples = 20000  # We will be training on 200 samples\n",
    "validation_samples = 5000  # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a 1D convnet\n",
    "\n",
    "In Keras, you would use a 1D convnet via the `Conv1D` layer, which has a very similar interface to `Conv2D`. It takes as input 3D tensors \n",
    "with shape `(samples, time, features)` and also returns similarly-shaped 3D tensors. The convolution window is a 1D window on the temporal \n",
    "axis, axis 1 in the input tensor.\n",
    "\n",
    "Let's build a simple 2-layer 1D convnet and apply it to the IMDB sentiment classification task that you are already familiar with.\n",
    "\n",
    "1D convnets are structured in the same way as their 2D counter-parts that you have used in Chapter 5: they consist of a stack of `Conv1D` \n",
    "and `MaxPooling1D` layers, eventually ending in either a global pooling layer or a `Flatten` layer, turning the 3D outputs into 2D outputs, \n",
    "allowing to add one or more `Dense` layers to the model, for classification or regression.\n",
    "\n",
    "One difference, though, is the fact that we can afford to use larger convolution windows with 1D convnets. Indeed, with a 2D convolution \n",
    "layer, a 3x3 convolution window contains 3*3 = 9 feature vectors, but with a 1D convolution layer, a convolution window of size 3 would \n",
    "only contain 3 feature vectors. We can thus easily afford 1D convolution windows of size 7 or 9.\n",
    "\n",
    "This is our example 1D convnet for the IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           22432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,029,665\n",
      "Trainable params: 1,029,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.8545 - acc: 0.5060 - val_loss: 0.6917 - val_acc: 0.5172\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.6753 - acc: 0.6338 - val_loss: 0.6752 - val_acc: 0.5562\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.6412 - acc: 0.7547 - val_loss: 0.6359 - val_acc: 0.7436\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.5758 - acc: 0.8141 - val_loss: 0.5425 - val_acc: 0.7852\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.4540 - acc: 0.8390 - val_loss: 0.4245 - val_acc: 0.8224\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.3659 - acc: 0.8656 - val_loss: 0.3784 - val_acc: 0.8518\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.3145 - acc: 0.8706 - val_loss: 0.3744 - val_acc: 0.8474\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.2761 - acc: 0.8563 - val_loss: 0.4082 - val_acc: 0.8130\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.2465 - acc: 0.8457 - val_loss: 0.3837 - val_acc: 0.8044\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.2223 - acc: 0.8213 - val_loss: 0.3944 - val_acc: 0.7816\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy was pretty good. Let's try it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 11s 422us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23737735465973617, 0.81352]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a good result!\n",
    "\n",
    "# You Try\n",
    "\n",
    "Now it is your turn to try some text classification problems using word embeddings and one dimensional convolutional neural networks. **You can do as many of these as you like**\n",
    "\n",
    "If you just do the basics you will get the low XP of the range. If you do a bit more (for example, compare gloVe embeddings to ones computed from the corpus) you can get up to the high end. \n",
    "\n",
    "\n",
    "## 20 News Group Corpus\n",
    "#### 35-45xp\n",
    "This is a classic dataset. You can find it at  [http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/). Download the bydate version. The task is to classify newsgroup posts by subject matter. \n",
    "## Amazon Electronics Reviews\n",
    "#### 35-45xp\n",
    "You can find this dataset at [http://jmcauley.ucsd.edu/data/amazon/](http://jmcauley.ucsd.edu/data/amazon/). One possibility is the electronics review dataset, but if you have your heart set on another, go for it. The reviews are in a loose json format so you will need to do some data munging. The ratings are on a scale of 1-5. I'd like to change those to positive reviews (4 or 5), negative reviews (1 or 2) and mixed (3). \n",
    "## Arabic Hotel Reviews\n",
    "#### 45-60xp\n",
    "This dataset is available at [https://github.com/hadyelsahar/large-arabic-sentiment-analysis-resouces/tree/master/datasets](https://github.com/hadyelsahar/large-arabic-sentiment-analysis-resouces/tree/master/datasets and the particular dataset I am looking at is HTL.csv. These are reviews written in Arabic. You are trying to predict a positive, negative, or mixed rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "\n",
    "Here's what you should take away from this notebook:\n",
    "\n",
    "* Word Embeddings are a useful representation for text analysis tasks\n",
    "* When you have a small dataset it might be useful to use pre-existing word embeddings such as GloVe.\n",
    "* 1d Convnets are the way to go for text classification tasks including sentiment analysis.\n",
    "\n",
    "## Acknowledgements\n",
    "This notebook contains many of the code samples and some text from Chapter 3, Section 5 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff) by Franois Chollet. \n",
    "\n",
    "\n",
    "#### Remix\n",
    "Remix by Ron Zacharski. Orginal Python notebook by Franois Chollet\n",
    "\n",
    "### MIT License\n",
    "\n",
    "Copyright (c) 2017 Franois Chollet\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
